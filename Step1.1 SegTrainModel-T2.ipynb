{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c278eb",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "\n",
    "引入Oneke相关的的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846159c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet, SegResNet, VNet, UNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0eedd8",
   "metadata": {},
   "source": [
    "### 数据集划分\n",
    "\n",
    "默认进行随机划分，使用最后的8个作为测试集合。\n",
    "\n",
    "`seg_idx = 1`可以通过修改seg_idx的值选择训练那个模型\n",
    "\n",
    "  1. `1`代表训练T1\n",
    "  2. `2`代表训练T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326fc2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from onekey_algo import get_param_in_cwd\n",
    "from onekey_algo.custom.components.Radiology import diagnose_3d_image_mask_settings\n",
    "\n",
    "root_dir = 'Y' + get_param_in_cwd('radio_dir')[1:]\n",
    "data_dir= os.path.join(root_dir, 'data')\n",
    "val_data_dir= os.path.join(root_dir, 'test')\n",
    "inference_dir= os.path.join(root_dir, 'test_results')\n",
    "model_root = os.path.join(root_dir, 'models')\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "# os.makedirs(inference_dir, exist_ok=True)\n",
    "roi_size = (96, 96, 48)\n",
    "\n",
    "# 这里选择任务类型\n",
    "sel_modal = 'MR-T2'\n",
    "train_files = []\n",
    "data = pd.read_csv(os.path.join(root_dir, 'label.csv'))\n",
    "# for i in data['ID']:\n",
    "for i in data[data['group'] == 'train']['ID']:\n",
    "    if os.path.exists(os.path.join(root_dir, sel_modal,'images', i)):\n",
    "        train_files.append({'image': os.path.join(root_dir, sel_modal, 'images', i), \n",
    "                            'label': os.path.join(root_dir, sel_modal, 'masks', i)})\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = []\n",
    "for i in data[data['group'] != 'train']['ID']:\n",
    "    if os.path.exists(os.path.join(root_dir, sel_modal, 'images', i)):\n",
    "        val_files.append({'image': os.path.join(root_dir, sel_modal, 'images', i), \n",
    "                          'label': os.path.join(root_dir, sel_modal, 'masks', i)})\n",
    "# val_files = val_files[:20]\n",
    "val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"训练集：{len(train_files)}，测试集：{len(val_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e33ab",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation\n",
    "\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. `LoadImaged` loads the spleen CT images and labels from NIfTI format files.\n",
    "1. `AddChanneld` as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "1. `Orientationd` unifies the data orientation based on the affine matrix.\n",
    "1. `Spacingd` adjusts the spacing by `pixdim=(1.5, 1.5, 2.)` based on the affine matrix.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "1. `RandAffined` efficiently performs `rotate`, `scale`, `shear`, `translate`, etc. together based on PyTorch affine transform.\n",
    "1. `EnsureTyped` converts the numpy array to PyTorch Tensor for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920baab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "#         Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1600,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=roi_size,\n",
    "            pos=1,\n",
    "            neg=2,\n",
    "            num_samples=4,\n",
    "#             image_key=\"image\",\n",
    "#             image_threshold=0,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]), \n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "#         Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1600,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136419a6",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "检查Transform以及相应的Dataloader。\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  And set `num_workers` to enable multi-threads during caching.  If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1, num_workers=6)\n",
    "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=12)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1, num_workers=6)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd95e14",
   "metadata": {},
   "source": [
    "#### 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddef87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
    "val_data_example = val_ds[2]\n",
    "print(f\"image shape: {val_data_example['image'].shape}\")\n",
    "plt.figure(\"image\", (12, 6))\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.title(f\"image channel {i}\")\n",
    "    plt.imshow(val_data_example[\"image\"][i, :, :, 65].detach().cpu(), cmap=\"gray\")\n",
    "plt.show()\n",
    "# also visualize the 3 channels label corresponding to this image\n",
    "print(f\"label shape: {val_data_example['label'].shape}\")\n",
    "plt.figure(\"label\", (6, 6))\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i + 1)\n",
    "    plt.title(f\"label channel {i}\")\n",
    "    plt.imshow(val_data_example[\"label\"][i, :, :, 65].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746817a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(val_data_example['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0004113",
   "metadata": {},
   "source": [
    "## 生成 Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceFocalLoss, DiceCELoss\n",
    "\n",
    "device = torch.device(f\"cuda:0\")\n",
    "mtype = 'unet'\n",
    "num_classes = 2\n",
    "in_channels = 1\n",
    "if mtype.lower() == 'unet':\n",
    "    #Unet\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=num_classes,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)\n",
    "elif mtype.lower() == 'segresnet':\n",
    "    #SegResNet\n",
    "    model = SegResNet(\n",
    "        blocks_down=[1, 2, 2, 4],\n",
    "        blocks_up=[1, 1, 1],\n",
    "        init_filters=16,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=num_classes,\n",
    "        dropout_prob=0.2,\n",
    "    ).to(device)\n",
    "elif mtype.lower() == 'unetr':\n",
    "    # UNETR\n",
    "    model = UNETR(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=num_classes,\n",
    "        img_size=roi_size,\n",
    "        feature_size=16,\n",
    "        hidden_size=768,\n",
    "        mlp_dim=3072,\n",
    "        num_heads=12,\n",
    "        pos_embed=\"perceptron\",\n",
    "        norm_name=\"instance\",\n",
    "        res_block=True,\n",
    "        dropout_rate=0.0,\n",
    "    ).to(device)\n",
    "elif mtype.lower() == 'vnet':\n",
    "    model = VNet(spatial_dims=3, \n",
    "                 in_channels=in_channels, \n",
    "                 out_channels=num_classes,\n",
    "                 dropout_prob=0.2, \n",
    "                 dropout_dim=3, \n",
    "                 bias=False).to(device)\n",
    "else:\n",
    "    raise ValueError(f'{mtype} not found!')\n",
    "\n",
    "print(f\"使用{mtype.upper()}进行训练！\")\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "if os.path.exists(os.path.join(model_root, f\"{mtype}_{sel_modal}.pth\")):\n",
    "    print('加载预训练模型...')\n",
    "    model.load_state_dict(torch.load(os.path.join(model_root, f\"{mtype}_{sel_modal}.pth\"), map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6812c",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "`max_epochs`最大迭代次数，int类型，默认： 600\n",
    "\n",
    "`val_interval` 多少次训练进行一次validation，默认： 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e388c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_epochs = 600\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=num_classes)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=num_classes)])\n",
    "early_stopping_epoch = 128\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "#         print(inputs.size())\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if step % 2 == 0:\n",
    "            print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            torch.save(model.state_dict(), os.path.join(model_root, f\"{mtype}_{sel_modal}-Epoch{epoch+1}.pth\"))\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \n",
    "                           os.path.join(model_root, f\"{mtype}_{sel_modal}.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            if epoch - best_metric_epoch > early_stopping_epoch:\n",
    "                print(f'Early Stop @{epoch+1}')\n",
    "                break\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641c3fc",
   "metadata": {},
   "source": [
    "### 打印训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.savefig(f'img/{mtype}_{sel_modal}_train_process.svg', bbox_inch='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b576a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import KeepLargestConnectedComponentd, RemoveSmallObjectsd\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from monai.config import KeysCollection\n",
    "from monai.transforms import MapTransform\n",
    "\n",
    "\n",
    "class RemoveSmallObjectsPerLabel(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, allow_missing_keys: bool = False,\n",
    "                 min_size=64, verbose: bool = False, force2: int = 0):\n",
    "        MapTransform.__init__(self, keys, allow_missing_keys)\n",
    "        self.min_size = min_size\n",
    "        self.verbose = verbose\n",
    "        self.force2 = force2\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for k in self.keys:\n",
    "            batch_data = []\n",
    "            for idx in range(data[k].shape[0]):\n",
    "                sel_data = np.array(data[k][idx]).astype(int)\n",
    "                print(sel_data.shape)\n",
    "                sel_data = sitk.GetImageFromArray(sel_data)\n",
    "                sitk.WriteImage(sel_data, f\"{idx}.nii.gz\")\n",
    "                cc_filter = sitk.ConnectedComponentImageFilter()\n",
    "                cc_filter.SetFullyConnected(True)\n",
    "                omask_array = sitk.GetArrayFromImage(cc_filter.Execute(sel_data))\n",
    "                unique_labels = np.unique(omask_array)\n",
    "                mask_label_voxels = {}\n",
    "                for ul in unique_labels:\n",
    "                    mask_label_voxels[ul] = np.sum(omask_array == ul)\n",
    "                mask_label_voxels = sorted(mask_label_voxels.items(), key=lambda x: x[1], reverse=True)\n",
    "                mask_postprocess = np.ones_like(omask_array)\n",
    "                for idx, (ul, cnt) in enumerate(mask_label_voxels):\n",
    "                    if cnt < self.min_size:\n",
    "                        mask_postprocess[omask_array == ul] = self.force2\n",
    "                if self.verbose:\n",
    "                    print(unique_labels, mask_label_voxels)\n",
    "                batch_data.append(mask_postprocess * data[k])\n",
    "            data[k] = np.array(batch_data)\n",
    "        return data\n",
    "\n",
    "val_t = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        EnsureTyped(keys=[\"image\"]),\n",
    "#         Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(1, 1, 1), mode=(\"bilinear\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=6000,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# val_transforms = Compose(\n",
    "#     [\n",
    "#         LoadImaged(keys=[\"image\"], allow_missing_keys=True),\n",
    "#         EnsureChannelFirstd(keys=[\"image\",], allow_missing_keys=True),\n",
    "# #         Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "#         Spacingd(keys=[\"image\",], pixdim=(0.5, 0.5, 3), mode=(\"bilinear\"), allow_missing_keys=True),\n",
    "#         ScaleIntensityRanged(\n",
    "#             keys=[\"image\"], a_min=0, a_max=2500,\n",
    "#             b_min=0.0, b_max=1.0, clip=True,\n",
    "#         ),\n",
    "#         CropForegroundd(keys=[\"image\",], source_key=\"image\", allow_missing_keys=True),\n",
    "#         EnsureTyped(keys=[\"image\",], allow_missing_keys=True),\n",
    "#     ]\n",
    "# )\n",
    "post_ori_t = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=val_t,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "            device=\"cpu\",\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        KeepLargestConnectedComponentd(keys='pred', num_components=4)\n",
    "#         RemoveSmallObjectsPerLabel(keys='pred', min_size=5000, verbose=True)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9dd76",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e29f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from onekey_algo import OnekeyDS\n",
    "from onekey_algo.segmentation3D.modelzoo.eval_3dsegmentation import init as init3d\n",
    "from onekey_algo.segmentation3D.modelzoo.eval_3dsegmentation import inference as inference3d\n",
    "\n",
    "root_dir = r'D:\\20240510-ChangBoWen'\n",
    "save_dir= os.path.join(root_dir, f'{mtype}_infer')\n",
    "model_root = os.path.join(root_dir, 'models')\n",
    "sel_modal = 'CLS2'\n",
    "\n",
    "mtype = 'segresnet'\n",
    "model_path = os.path.join(model_root, f'{mtype}_{sel_modal}.pth')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# for i in prefetch:\n",
    "#     mask_img = i.replace('.nii.gz', '.mask.nii.gz')\n",
    "#     if not os.path.exists(mask_img):\n",
    "#         data.append(i)\n",
    "num_classes = 4\n",
    "m, t, d = init3d('SegResNet', model_path=model_path, num_classes=num_classes, roi_size=roi_size)\n",
    "d = 'cuda:0'\n",
    "m = m.to(d)\n",
    "data = glob.glob(os.path.join(root_dir, r'images', '*.nii.gz'))\n",
    "\n",
    "inference3d(data, model, (val_t, post_ori_t), d, roi_size=roi_size, save_dir=save_dir)\n",
    "\n",
    "# for data_ in data:\n",
    "#     inference3d([data_], m, (val_t, post_ori_t), d, \n",
    "#                 roi_size=roi_size, save_dir=os.path.dirname(data_), save_name=data_.replace('.nii.gz', '.infer.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from monai.metrics import compute_average_surface_distance, compute_hausdorff_distance\n",
    "\n",
    "def calc_dice(p_cls, l_cls):\n",
    "    # cal the inter & conv\n",
    "    s = p_cls + l_cls\n",
    "    inter = len(np.where(s >= 2)[0])\n",
    "    conv = len(np.where(s >= 1)[0]) + inter\n",
    "    try:\n",
    "        dice = 2.0 * inter / conv\n",
    "    except:\n",
    "        print(\"conv is zeros when dice = 2.0 * inter / conv\")\n",
    "        dice = None\n",
    "    return dice\n",
    "\n",
    "def calc_iou(p_cls, l_cls):\n",
    "    # cal the inter & conv\n",
    "    s = p_cls + l_cls\n",
    "    inter = len(np.where(s >= 2)[0])\n",
    "    conv = len(np.where(s >= 1)[0])\n",
    "    try:\n",
    "        iou = inter / conv\n",
    "    except:\n",
    "        print(\"conv is zeros when dice = 2.0 * inter / conv\")\n",
    "        iou = None\n",
    "    return iou\n",
    "    \n",
    "def calc_sa(p_cls, l_cls):\n",
    "    # cal the inter & conv\n",
    "    error = np.bitwise_xor(p_cls, l_cls) & l_cls\n",
    "    try:\n",
    "        sa = 1 - np.sum(error) / np.sum(l_cls)\n",
    "    except:\n",
    "        print(\"SA segmentation is error!\")\n",
    "        sa = None\n",
    "    return sa\n",
    "\n",
    "def calc_os(p_cls, l_cls):\n",
    "    # cal the inter & conv\n",
    "    error = np.bitwise_xor(p_cls, l_cls) & p_cls\n",
    "    try:\n",
    "        over_s = np.sum(error) / (np.sum(l_cls) + np.sum(p_cls))\n",
    "    except:\n",
    "        print(\"Over segmentation is error!\")\n",
    "        over_s = None\n",
    "    return over_s\n",
    "\n",
    "def calc_us(p_cls, l_cls):\n",
    "    # cal the inter & conv\n",
    "    error = np.bitwise_xor(p_cls & l_cls, l_cls)\n",
    "    try:\n",
    "        us = np.sum(error) / (np.sum(l_cls) + np.sum(np.bitwise_xor(p_cls, l_cls) & p_cls))\n",
    "    except:\n",
    "        print(\"Under segmentation is error!\")\n",
    "        us = None\n",
    "    return us\n",
    "\n",
    "def calc_asd(p_cls, l_cls):\n",
    "    asd = compute_average_surface_distance(p_cls[np.newaxis, np.newaxis, :], l_cls[np.newaxis, np.newaxis, :])\n",
    "    return float(asd)\n",
    "\n",
    "def calc_hausdorff_distance(p_cls, l_cls): \n",
    "    hd = compute_hausdorff_distance(p_cls[np.newaxis, np.newaxis, :], l_cls[np.newaxis, np.newaxis, :])\n",
    "    return float(hd)\n",
    "\n",
    "def seg_eval(pred, label, clss=[0, 1]):\n",
    "    \"\"\"\n",
    "    calculate the dice between prediction and ground truth\n",
    "    input:\n",
    "        pred: predicted mask\n",
    "        label: groud truth\n",
    "        clss: eg. [0, 1] for binary class\n",
    "    \"\"\"\n",
    "    Ncls = len(clss)\n",
    "    eval_matric = [None] * Ncls\n",
    "    [depth, height, width] = pred.shape\n",
    "    for idx, cls in enumerate(clss):\n",
    "        # binary map\n",
    "        pred_cls = np.zeros([depth, height, width], dtype=np.uint8)\n",
    "        pred_cls[np.where(pred == cls)] = 1\n",
    "        label_cls = np.zeros([depth, height, width], dtype=np.uint8)\n",
    "        label_cls[np.where(label == cls)] = 1\n",
    "\n",
    "        metric = [calc_dice(pred_cls, label_cls), calc_iou(pred_cls, label_cls), \n",
    "                  calc_sa(pred_cls, label_cls), calc_os(pred_cls, label_cls), calc_us(pred_cls, label_cls), \n",
    "#                   calc_asd(pred_cls, label_cls), calc_hausdorff_distance(pred_cls, label_cls)\n",
    "                 ]\n",
    "        eval_matric[idx] = metric\n",
    "\n",
    "    return eval_matric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98a001",
   "metadata": {},
   "source": [
    "### 后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = ['unet', 'unetr', 'vnet']\n",
    "cohort_metric = []\n",
    "metric_spec = []\n",
    "tn = None\n",
    "for model in models:\n",
    "    root = os.path.join(get_param_in_cwd('radio_dir'), sel_modal, f'{model}_infer')\n",
    "    metric_names = ['Dice', 'mIOU', 'SA', 'OS', 'US']\n",
    "\n",
    "    for fs in [train_files[:tn], val_files[:tn]]:\n",
    "        all_metrics = []\n",
    "        for gt in fs:\n",
    "            gt_mask = gt['label']\n",
    "            pred_mask = os.path.join(root, os.path.basename(gt_mask))\n",
    "            all_metrics.append(seg_eval(sitk.GetArrayFromImage(sitk.ReadImage(pred_mask)),\n",
    "                                        sitk.GetArrayFromImage(sitk.ReadImage(gt_mask)), clss=[0, 1]))\n",
    "        metric = pd.DataFrame(np.mean(np.array(all_metrics), axis=1), columns=metric_names)\n",
    "        cohort_metric.append(pd.DataFrame(metric.mean(axis=0)).T)\n",
    "        metric['model'] = model\n",
    "        info = pd.concat([pd.DataFrame([os.path.basename(f['image']) for f in fs[:tn]], columns=['ID']), metric], axis=1)\n",
    "        metric_spec.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.concat(metric_spec, axis=0)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "info.to_csv(f'data/{sel_modal}_infer.csv', index=False)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a436b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(info, pd.read_csv('group.csv'), on='ID', how='left').groupby(['group', 'model']).agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb827ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
