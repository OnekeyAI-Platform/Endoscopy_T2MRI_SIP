{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c9708b",
   "metadata": {},
   "source": [
    "## 打印可视化界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb2b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from onekey_algo.datasets.image_loader import default_loader\n",
    "from onekey_algo.custom.components.comp2 import show_cam_on_image\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from onekey_algo import get_param_in_cwd\n",
    "from onekey_algo.custom.components.comp2 import extract, init_from_model, init_from_onekey\n",
    "from onekey_algo.utils.MultiProcess import MultiProcess\n",
    "import numpy as np\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import monai\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "epoch_mapping = {'resnet101': {'MR-CE_anno': 37, 'MR-CE': 32, 'MR-T2_anno': 48, 'MR-T2': 42, 'endoscope': 25,  'endoscope_anno': 38, },\n",
    "                 'densenet121': {'MR-CE_anno': 45, 'MR-CE': 23, 'MR-T2_anno': 40, 'MR-T2': 44, 'endoscope': 28, 'endoscope_anno': 38, },\n",
    "                 'CrossFormer': {'MR-CE_anno': 253, 'MR-CE': 244, 'MR-T2_anno': 285, 'MR-T2': 206,\n",
    "                                 'endoscope': 141, 'endoscope_anno': 110, },}\n",
    "\n",
    "\n",
    "def viz_sample(samples, thread_id, model_root, force_epoch):\n",
    "    model, transformer, device = init_from_onekey(os.path.join(model_root, 'viz'), \n",
    "                                                  force_pth=os.path.join(model_root, f'train/training-params-{8*force_epoch}.pth'))\n",
    "    for n, m in model.named_modules():\n",
    "        print('Feature name:', n, \"|| Module:\", m)\n",
    "    target_layer = \"layer4.1.conv2\"\n",
    "    target_layer = 'features.denseblock4.denselayer16.conv2' if 'densenet' in model_root else 'layers.3.1.layers.1.3.4'\n",
    "#     return \n",
    "    gradcam = monai.visualize.GradCAM(nn_module=model, target_layers=target_layer)\n",
    "#     return\n",
    "    viz_dir = os.path.join(model_root, 'Grad-CAM')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    for sample in samples:\n",
    "        if os.path.exists(os.path.join(viz_dir, os.path.basename(sample))):\n",
    "            continue\n",
    "        img = default_loader(sample)\n",
    "        sample_ = transformer(img)\n",
    "        sample_  = sample_.view(1, *sample_.size()).to(device)\n",
    "        res_cam = gradcam(x=sample_, class_idx=None)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4), facecolor='white')\n",
    "    #     axes[0].imshow(-res_cam[0][0].cpu(), cmap='jet')\n",
    "        axes[0].imshow(img.resize(sample_.size()[2:]))\n",
    "        axes[0].axis('off')\n",
    "    #     plt.savefig(f\"viz/{os.path.basename(sample).replace('.png', '_se.png')}\", bbox_inches = 'tight')\n",
    "    #     plt.show()\n",
    "    #     plt.figure(figsize=(10, 10))\n",
    "    #     plt.axis('off')\n",
    "        imshow = axes[1].imshow(-res_cam[0][0].cpu(),cmap='jet')\n",
    "        axes[1].axis('off')\n",
    "        imshow = axes[2].imshow(show_cam_on_image(img.resize(sample_.size()[2:]), -res_cam[0][0].cpu(), use_rgb=True, reverse=False), \n",
    "                                cmap='jet')\n",
    "        axes[2].axis('off')\n",
    "        cax = fig.add_axes([0.92, 0.17, 0.02, axes[2].get_position().height]) \n",
    "        plt.colorbar(imshow, cax=cax)\n",
    "        plt.savefig(f'{viz_dir}/{os.path.basename(sample).replace(\".npy\", \".png\")}', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "for model in ['densenet121',]:\n",
    "    for modal in epoch_mapping[model].keys():\n",
    "        if 'endoscope' in modal:\n",
    "            prefix = 'fcn_crop' if 'anno' in modal else 'crop'\n",
    "            m = modal.split('_')[0]\n",
    "            samples = glob(os.path.join(rf'Y:\\20240320-RenJiLiang\\Segmentation\\endoscope_coco\\{prefix}', '*'))\n",
    "        else:\n",
    "            continue\n",
    "            prefix = 'vnet_crop' if 'anno' in modal else 'crop'\n",
    "            samples = glob(os.path.join(rf'Y:\\20240320-RenJiLiang\\{modal.split(\"_\")[0]}\\{prefix}', '*'))\n",
    "        model_root = rf'Y:\\20240320-RenJiLiang\\Classification\\{modal}\\CV-6\\{model}'\n",
    "        force_epoch = epoch_mapping[model][modal]\n",
    "        random.shuffle(samples)\n",
    "        viz_sample(samples, thread_id=1, model_root=model_root, force_epoch=force_epoch+1)\n",
    "# MultiProcess(func=viz_sample, samples=samples, num_process=1).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071d408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
